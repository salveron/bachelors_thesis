\chapter{Computational ASA}\label{chapter:casa}

Now, having described all the underlying concepts from different fields of science in previous chapters, it is time to finally focus on computational auditory scene analysis. CASA is said to be the study that groups practical, programmable solutions for auditory scene analysis problems, or the study of ASA by computational means. CASA systems are used primarily for source separation, meaning that they are machine listening systems that aim to separate "target" sounds from mixtures, just like people do when try to focus on a specific sound and not to be distracted by others. In that CASA systems differ from systems for blind signal separation â€“ they try to mimic (at least to some extent) the mechanisms inside the human ear, which were discussed in chapter~\ref{chapter:biology}. In this chapter, main principles of CASA systems will be described, along with a typical architecture, goals and applications. In the second part, major works that use computational auditory scene analysis for source separation will be reviewed and compared.

\section{Principles, Goals and Applications}

Now, having the definition of CASA above, to be able to limit the requirements to the models it is necessary to describe the principles of CASA and common concepts across different systems. As the most major one, one could pick the restriction of number of microphones used in the input. Being based on the mechanisms of the human auditory system, CASA models only use recordings from one or two microphones, thus being split to monaural and binaural. Monaural models are researched better, but can't be used for extracting features based on the location of the sound, which is possible to some extent in binaural models, when time differences between the two recordings might be used.\\

To discuss the goals of CASA, it is useful to refer to the goals of ASA. According to Bregman \cite{Bregman1990}, the primary goal of auditory scene analysis is to produce separate streams from the auditory input. Here, the term "stream" refers to a representation of a distinct sound source in the acoustic environment, but, for example in \cite{Wang2006}, the authors also use it when talking about these representations in computer memory.\\

For CASA, Wang \cite{Wang2006} proposed that the goal should be to find an ideal binary mask (IBM) for the time-frequency (T-F) representation of the input. If the input is split into T-F units, where time is on horizontal axis and frequency on vertical, an IBM is a binary matrix that has ones in places where the target sound is stronger, and zeroes elsewhere for background units. Ideal binary masks will be discussed in more detail in the following section.\\

In \cite{Szabo2016}, the authors say that different models of CASA vary in their fundamental goals. Some of them are inspired by various biological experiments \cite{Wang2008}\cite{Boes2011}, while others are trying to address the cocktail party problem in natural environments \cite{Elhilali2008}. Some models try to explicitly simulate perceptual data, but others may refer to perception only very slightly. The expected output for the system implemented in this thesis is to find an IBM to be able to mask noisy background in monophonic piano music.\\

Also in \cite{Szabo2016}, the authors organize the models into three groups based on their modeling principles: Bayesian inference rules, neural processing or temporal coherence. Bayesian models use Bayesian inference rules and predictive mechanisms as the primary principles, and state vectors to represent the auditory space. Neural models try to represent the objects as units, whose properties are inspired by neurons or neural networks. Temporal coherence models are based on the fact that acoustic features of sounds from the same source tend to occur together.\\

Possible applications of CASA are quite various. Aside from pure scientific interest, CASA systems bring new solutions to the problems of speech recognition, automatic music transcription, hearing prostheses, 

\section{Typical Architecture}

The architecture described in the next subsections is based on \cite{Wang2006}, \cite{Jasti2020} and \cite{Virtanen2012}, though it is impossible to say that it is used in all systems -- in different sources the authors use different approaches and methods, and thus different structures of the models.

\subsection{Peripheral Analysis}

Usually, a model for computational auditory scene analysis begins with peripheral analysis of the input sound. Here, based on the knowledge that ASA is a two-stage process, the first, segmentation stage begins. The expected result of this stage usually includes a time-frequency representation of the input sound -- a set of so-called T-F units. Since the models try to mimic the human cochlea, the researchers have given it the most attention, and the most common outcome here is a cochleagram.\\

Cochleagram is produced by a filterbank of $N$ gammatone filters. Gammatone filters were picked as the most close ones to mimic points on the basilar membrane, so different filters from the filterbank represent different points on it. The center frequencies of the filters are not spread linearly in equal intervals, but usually on the ERB (equivalent rectangular bandwidth) scale, which tries to address human hearing.

\subsection{Feature Extraction}
\subsection{Grouping}
\subsection{Resynthesis}



\section{Major Works}
