\chapter{Computational ASA}\label{chapter:casa}

Now, having described all the underlying concepts from different fields of science in previous chapters, it is time to finally focus on computational auditory scene analysis. CASA is said to be the study that groups practical, programmable solutions for auditory scene analysis problems, or the study of ASA by computational means. CASA systems are used primarily for source separation, meaning that they are machine listening systems that aim to separate "target" sounds from mixtures, just like people do when try to focus on a specific sound and not to be distracted by others. In that CASA systems differ from systems for blind signal separation â€“ they try to mimic (at least to some extent) the mechanisms inside the human ear, which were discussed in chapter~\ref{chapter:biology}. In this chapter, main principles of CASA systems will be described, along with a typical architecture, goals and applications. In the second part, major works that use computational auditory scene analysis for source separation will be reviewed and compared.

\section{Principles, Goals and Applications}

Having the definition of CASA above, to be able to limit the requirements to the models it is necessary to describe the principles of CASA and common concepts across different systems. As the most major one, one could pick the restriction of number of microphones used in the input. Being based on the mechanisms of the human auditory system, CASA models only use recordings from one or two microphones, thus being split to monaural and binaural. Monaural models are researched better, but can't be used for extracting features based on the location of the sound, which is possible to some extent in binaural models, when time differences between the two recordings might be used.\\

To discuss the goals of CASA, it is useful to refer to the goals of ASA. According to Bregman~\cite{Bregman1990}, the primary goal of auditory scene analysis is to produce separate streams from the auditory input. Here, the term "stream" refers to a representation of a distinct sound source in the acoustic environment, but, for example in \cite{Wang2006}, the authors also use it when talking about these representations in computer memory.\\

For CASA, Wang \cite{Wang2006} proposed that the goal should be to find an ideal binary mask (IBM) for the time-frequency (T-F) representation of the input. If the input is split into T-F units, where time is on horizontal axis and frequency on vertical, an IBM is a binary matrix that has ones in places where the target sound is stronger, and zeroes elsewhere for background units. Ideal binary masks will be discussed in more detail in the following section.\\

The research of CASA systems and their applications in science \cite{Szabo2016} have been quite diverse recently. Some of the models are inspired by various biological experiments \cite{Wang2008}\cite{Boes2011}, while others are trying to address the cocktail party problem in natural environments \cite{Elhilali2008}. Some models try to explicitly simulate perceptual data, but others may refer to perception only very slightly. The expected output for the system implemented in this thesis is to find an IBM to be able to mask noisy background in monophonic piano music.\\

Aside from pure scientific interest, CASA systems find useful applications in everyday problems \cite{Wang2006}. Some of them are listed below.

\begin{description}
	\item\textbf{Speech recognition.} Apparently, the most popular field, where CASA systems have been used. Many speech recognition systems have performance losses in acoustic environments, where multiple sources of sound are present. The development is often put in contrast with computer vision systems that basically fulfill the same purpose, but for another human sense.
	\item\textbf{Automatic music transcription.} A complex problem on its own (even human experts can come up with different solutions) becomes more complicated when multiple musical instruments are involved and need to be transcribed separately. CASA can bring new solutions to these problems.
	\item\textbf{Hearing prostheses.} Modern hearing aids made for people suffering from hearing loss don't separate speech in noisy environments, amplifying the noisy background too. CASA could address this problem to filter the noise out at least to some extent.
	\item\textbf{Audio information retrieval.} Recordings on the Internet usually contain mixtures of sounds from different sources, thus it is necessary to separate them to be able to search efficiently.
\end{description}

\section{Typical Architecture}

The architecture described in the next subsections is based on \cite{Wang2006}, \cite{Jasti2020} and \cite{Virtanen2012}, though it is impossible to say that it is used in all systems -- in different sources the authors use different approaches and methods, and thus different structures of the models.

\subsection{Peripheral Analysis}

Usually, a model for computational auditory scene analysis begins with peripheral analysis of the input sound. Here, based on the knowledge that ASA is a two-stage process, the first, segmentation stage begins. The expected result of this stage usually includes a time-frequency representation of the input sound -- a set of so-called T-F units. Since the models try to mimic the human cochlea, the researchers have given it the most attention, and the most common outcome here is a cochleagram.\\

Cochleagram is produced by a filterbank of $N$ gammatone filters. Gammatone filters were picked as the most close ones to mimic points on the basilar membrane, so different filters from the filterbank represent different points on it. The center frequencies of the filters are not spread linearly in equal intervals, but usually on the ERB (equivalent rectangular bandwidth) scale, which tries to address human hearing.

\subsection{Feature Extraction}
\subsection{Grouping}
\subsection{Resynthesis}



\section{Major Works}
